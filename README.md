# PyDocQ&A ğŸ§   
**An Optimized RAG System for Python Documentation**

PyDocQ&A is a Retrieval-Augmented Generation (RAG) application that enables fast, accurate question answering over Python documentation using semantic search and a transformer-based language model.  
The system is designed with a clear separation between **offline indexing** and **online querying** to ensure low-latency responses.

---

## ğŸš€ Features

- Semantic search over Python documentation using **FAISS**
- Efficient text embeddings via **Sentence Transformers**
- Transformer-based answer generation using **FLAN-T5**
- One-time offline embedding and indexing for performance optimization
- Interactive **Streamlit** chat interface
- Modular, production-style project structure

---

## ğŸ—ï¸ Architecture Overview

```
Python Docs (.txt)
â†“
Document Chunking
â†“
Sentence Embeddings
â†“
FAISS Vector Index (Persisted)
â†“
Query Embedding
â†“
Top-K Semantic Retrieval
â†“
Context Injection
â†“
LLM Answer Generation
```
---

## ğŸ“‚ Project Structure

```
PyDocQ&A/
â”‚
â”œâ”€â”€ artifacts/
â”‚ â”œâ”€â”€ faiss.index # FAISS vector index
â”‚ â””â”€â”€ chunks.pkl # Chunked document metadata
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ load_and_chunk.py # Load and chunk text documents
â”‚ â”œâ”€â”€ embeddings.py # Create sentence embeddings
â”‚ â”œâ”€â”€ build_index.py # One-time FAISS index builder
â”‚ â”œâ”€â”€ qa_chain.py # CLI-based question answering
â”‚ â””â”€â”€ app.py # Streamlit UI application
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Tech Stack

- **Python**
- **FAISS** â€“ Vector similarity search
- **SentenceTransformers** â€“ Text embeddings
- **Transformers (FLAN-T5)** â€“ Answer generation
- **Streamlit** â€“ Web UI
- **LangChain** â€“ Document and text utilities

---

ğŸ“Œ Data & Artifacts Note

Raw Python documentation files are excluded from the repository to keep it lightweight and reproducible.

Precomputed FAISS indexes and processed artifacts are included to enable instant evaluation and fast querying without rebuilding embeddings.

ğŸ“ˆ Performance Optimization
Stage	Naive Approach	Optimized Approach
Embedding	Every run	One-time offline
Indexing	Every run	Persisted FAISS
Query latency	Minutes	~1â€“2 seconds
Startup time	High	Low
